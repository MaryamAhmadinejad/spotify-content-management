services:
  # Kafka Cluster
  kafka:
    image: bitnami/kafka:latest
    ports:
      - "9092:9092"
    environment:
    - KAFKA_CFG_PROCESS_ROLES=controller,broker  # Order matters for some images
    - KAFKA_CFG_NODE_ID=1
    - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
    - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
    - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
    - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
    - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER  # Critical missing line
    - ALLOW_PLAINTEXT_LISTENER=yes
    deploy:
      resources:
        limits:
          memory: 1.5G
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics.sh --bootstrap-server localhost:9092 --list || exit 1"]
      interval: 15s
      timeout: 20s
      retries: 10

  # Kafka UI 
  kafka-ui:
    image: tchiotludo/akhq
    ports:
      - "8085:8080"
    environment:
      AKHQ_CONFIGURATION: |
        akhq:
          connections:
           local:
             properties:
               bootstrap.servers: "kafka:9092"
          security:
           default:
              admin:
                username: admin
                password: admin
    depends_on:
      - kafka

  # Event Generator
  eventsim:
    image: khoramism/event-generator-eventsim:1.2
    environment:
      - BOOTSTRAP_SERVERS=kafka:9092  # Matches Kafka service name
      - KEY_SERIALIZER=org.apache.kafka.common.serialization.ByteArraySerializer
      - VALUE_SERIALIZER=org.apache.kafka.common.serialization.ByteArraySerializer
      - SECURITY_PROTOCOL=PLAINTEXT
      - SASL_JAAS_CONFIG=   # Provide an empty value since not using SASL
      - SASL_MECHANISM=PLAIN  # Define a default value (or empty string) for SASL_MECHANISM
      - CLIENT_DNS_LOOKUP=use_all_dns_ips
      - SESSION_TIMEOUT_MS=45000
      - ACKS=all
    command: sh -c "sleep 20 && ./bin/eventsim -c configs/Guitar-config.json --continuous --from 200 --nusers 2000 -k 1"
    depends_on:
      - kafka
      

  # Spark Standalone Cluster
  spark-master:
    image: bitnami/spark:latest
    ports:
      - "8080:8080"  # Spark Master UI
      - "7077:7077"  # Spark Master Port
      - "4040:4040"  # Spark Application UI
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./src:/app/src
      # - ./config:/app/config

  spark-worker:
    image: bitnami/spark:latest
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=2g
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./src:/app/src
      # - ./config:/app/config
    depends_on:
      - spark-master

  spark-processor:
    build: .
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - HDFS_NAMENODE=namenode:9000
      - SPARK_MASTER=spark://spark-master:7077
      - HADOOP_USER_NAME=root
    volumes:
      - ./src:/app/src  # Mount the source code
      # - ./config:/app/config
    depends_on:
      - kafka
      - namenode
      - spark-master
      - datanode 
    command: [
      "spark-submit",
      "--master", "spark://spark-master:7077",
      "--packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0",  
      "/app/src/kafka_to_hdfs.py"
      ]

  # HDFS Cluster
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    ports:
      - "9870:9870"  # HDFS UI
      - "9000:9000"
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=eventsim
    env_file:
      - ./hadoop.env
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9870/ || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    env_file:
      - ./hadoop.env
    depends_on:
      - namenode
    environment:
      - HADOOP_USER_NAME=root

volumes:
  hadoop_namenode:
  hadoop_datanode:
